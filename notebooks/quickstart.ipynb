{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xctopus - Quick Start for Contributors\n",
    "\n",
    "Minimal notebook to run Xctopus clustering layer. Assumes localhost environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "from xctopus.main import initialize_components, process_dataset\n",
    "from xctopus.fusion import fuse_knowledge_nodes\n",
    "from xctopus.settings import EMBEDDING_DIM, DEVICE, DTYPE\n",
    "\n",
    "print(f\"Device: {DEVICE}, Dtype: {DTYPE}, Embedding Dim: {EMBEDDING_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_PATH = \"../datasets/your_dataset.csv\"  # Update with your dataset path\n",
    "TEXT_COLUMNS = ['text']  # Update with your text column name(s)\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "if isinstance(TEXT_COLUMNS, list) and len(TEXT_COLUMNS) > 1:\n",
    "    texts = df[TEXT_COLUMNS].apply(lambda row: \" \".join(str(val) for val in row if pd.notna(val)), axis=1).tolist()\n",
    "else:\n",
    "    text_col = TEXT_COLUMNS[0] if isinstance(TEXT_COLUMNS, list) else TEXT_COLUMNS\n",
    "    texts = df[text_col].astype(str).fillna('').str.strip().tolist()\n",
    "    texts = [t for t in texts if len(t) >= 3]\n",
    "\n",
    "print(f\"Loaded {len(texts)} texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embeddings_path = DATASET_PATH.replace('.csv', '_embeddings.npy')\n",
    "\n",
    "if Path(embeddings_path).exists():\n",
    "    embeddings_np = np.load(embeddings_path)\n",
    "    print(f\"Loaded embeddings: {embeddings_np.shape}\")\n",
    "else:\n",
    "    model = SentenceTransformer(EMBEDDING_MODEL, device=DEVICE)\n",
    "    embeddings_np = model.encode(texts, convert_to_numpy=True, show_progress_bar=True, batch_size=32, normalize_embeddings=True)\n",
    "    np.save(embeddings_path, embeddings_np)\n",
    "    print(f\"Generated and saved embeddings: {embeddings_np.shape}\")\n",
    "\n",
    "embeddings = [torch.from_numpy(emb).to(device=DEVICE, dtype=DTYPE) for emb in embeddings_np]\n",
    "print(f\"Converted to {len(embeddings)} FP16 tensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "repository, filter_bayesian, orchestrator = initialize_components()\n",
    "print(\"Components initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process embeddings\n",
    "process_dataset(embeddings, repository, filter_bayesian, orchestrator, progress_interval=100)\n",
    "print(\"Processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fusion\n",
    "fusion_stats = fuse_knowledge_nodes(repository, orchestrator, progress_interval=10)\n",
    "print(f\"Fusion: {fusion_stats['initial_kns']} -> {fusion_stats['final_kns']} KNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final statistics\n",
    "signatures = repository.get_all_signatures()\n",
    "print(f\"Final KNs: {len(signatures)}\")\n",
    "print(f\"Total mass: {sum(s['mass'] for s in signatures)}\")\n",
    "print(f\"Avg mass: {sum(s['mass'] for s in signatures) / len(signatures):.1f}\")\n",
    "print(f\"Avg variance: {sum(s['variance'] for s in signatures) / len(signatures):.4f}\")\n",
    "\n",
    "repository.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

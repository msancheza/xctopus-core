{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [XCTOPUS] Xctopus - Training and Evaluation\n",
    "\n",
    "\n",
    "\n",
    "## <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-target\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 12m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0\" /><path d=\"M12 12m-5 0a5 5 0 1 0 10 0a5 5 0 1 0 -10 0\" /><path d=\"M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0\" /></svg> Interactive Visual Tool\n",
    "\n",
    "\n",
    "\n",
    "This notebook is a **complete visual tool** for:\n",
    "\n",
    "- [OK] **Training**: Run clustering with customizable configuration\n",
    "\n",
    "- [OK] **Evaluation**: Evaluate clustering quality and visualize results\n",
    "\n",
    "- [OK] **Automatic Analysis**: Intelligent interpretation of results with recommendations\n",
    "\n",
    "- [OK] **Advanced Visualizations**: Interactive charts, tables and dashboards\n",
    "\n",
    "- [OK] **Comparison**: Test multiple configurations side by side\n",
    "\n",
    "- [OK] **Export**: Save successful configurations for reuse\n",
    "\n",
    "- [OK] **Adjust parameters**: Modify thresholds, epochs, and other parameters easily\n",
    "\n",
    "- [OK] **Change dataset**: Test with different datasets\n",
    "\n",
    "\n",
    "\n",
    "### [*] Recommended Workflow:\n",
    "\n",
    "1. **Configuration** ‚Üí Adjust parameters in the configuration section\n",
    "\n",
    "2. **Training** ‚Üí Run clustering\n",
    "\n",
    "3. **Automatic Analysis** ‚Üí Review recommendations\n",
    "\n",
    "4. **Evaluation** ‚Üí Run audit and evaluation\n",
    "\n",
    "5. **Visualizations** ‚Üí Explore charts and dashboards\n",
    "\n",
    "6. **Export** ‚Üí Save successful configurations\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-notes\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M5 3m0 2a2 2 0 0 1 2 -2h10a2 2 0 0 1 2 2v14a2 2 0 0 1 -2 2h-10a2 2 0 0 1 -2 -2z\" /><path d=\"M9 7l6 0\" /><path d=\"M9 11l6 0\" /><path d=\"M9 15l4 0\" /></svg> Table of Contents\n",
    "\n",
    "\n",
    "\n",
    "1. **<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-package\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 3l8 4.5l0 9l-8 4.5l-8 -4.5l0 -9l8 -4.5\" /><path d=\"M12 12l8 -4.5\" /><path d=\"M12 12l0 9\" /><path d=\"M12 12l-8 -4.5\" /></svg> Setup and Imports** - Initial setup and libraries\n",
    "\n",
    "2. **[*] Configuration** - Dataset, clustering and evaluation parameters\n",
    "\n",
    "3. **<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-number-1\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M13 20v-16l-5 5\" /></svg> Training (Clustering)** - Clustering execution with the specified configuration\n",
    "\n",
    "4. **<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-number-2\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M10 8a2 2 0 1 1 4 0c0 .738 -.405 1.376 -1 1.723l-3 2.277v3h4\" /></svg> Evaluation** - Audit and evaluation of clustering quality\n",
    "\n",
    "5. **[*] Visualizations** - Generated charts (embeddings, learning progress, LoRA)\n",
    "\n",
    "6. **<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-notes\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M5 3m0 2a2 2 0 0 1 2 -2h10a2 2 0 0 1 2 2v14a2 2 0 0 1 -2 2h-10a2 2 0 0 1 -2 -2z\" /><path d=\"M9 7l6 0\" /><path d=\"M9 11l6 0\" /><path d=\"M9 15l4 0\" /></svg> Final Summary** - Summary of results and metrics\n",
    "\n",
    "7. **[*] Automatic Results Analysis** - Intelligent interpretation with recommendations\n",
    "\n",
    "8. **[*] Configuration Comparison** - Comforr m√∫ltiples configuraciones lado a lado\n",
    "\n",
    "9. **<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-chart-line\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M4 19l16 0\" /><path d=\"M4 15l4 -6l4 2l4 -5l4 4\" /></svg> Training Progress Charts** - Evolution of loss and number of clusters\n",
    "\n",
    "10. **[*] Results Dashboard** - Consolidated interactive HTML view\n",
    "\n",
    "11. **<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-device-floppy\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M6 4h10l4 4v10a2 2 0 0 1 -2 2h-12a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2\" /><path d=\"M12 14m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0\" /><path d=\"M14 4l0 4l-6 0l0 -4\" /></svg> Exportar Configuration Exitosa** - Save successful configurations in YAML\n",
    "\n",
    "12. **[TIP] Tips and Best Practices** - Parameter tuning and interpretation guide\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-package\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 3l8 4.5l0 9l-8 4.5l-8 -4.5l0 -9l8 -4.5\" /><path d=\"M12 12l8 -4.5\" /><path d=\"M12 12l0 9\" /><path d=\"M12 12l-8 -4.5\" /></svg> Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML, Image, Markdown\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Image, Markdown\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "# Add src to path\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent\n",
    "src_path = project_root / 'src'\n",
    "sys.path.insert(0, str(src_path))\n",
    "# Import Xctopus\n",
    "from xctopus import XctopusPipeline\n",
    "from xctopus.pipeline import PipelineConfig\n",
    "# Configure matplotlib for better visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "print(f\"[*] Project root: {project_root}\")\n",
    "print(f\"[OK] XctopusPipeline imported correctly\")\n",
    "print(f\"[OK] Visualization libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [*] Configuration\n",
    "\n",
    "Adjust these parameters according to your needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset: datasets/20newsgroups_sample_500.csv\n",
      "ü§ñ Modelo: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATASET CONFIGURATION\n",
    "# ============================================================================\n",
    "# Dataset path (you can change this)\n",
    "DATASET_PATH = 'datasets/20newsgroups_sample_500.csv'  # Change here\n",
    "# Text columns (auto-detected if not specified)\n",
    "TEXT_COLUMNS = ['text']  # None for auto-detection\n",
    "# Embedding model\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'  # Fast and sufficient\n",
    "# EMBEDDING_MODEL = 'sentence-transformers/all-mpnet-base-v2'  # More powerful but slower\n",
    "print(f\"[*] Dataset: {DATASET_PATH}\")\n",
    "print(f\"[*] Model: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Configuraci√≥n de Clustering:\n",
      "   - Thresholds: 0.6 / 0.4 / 0.7\n",
      "   - MIN_CLUSTER_SIZE: 3\n",
      "   - MERGE_SIMILARITY_THRESHOLD: 0.45\n",
      "   - Epochs: 10\n",
      "   - Adaptive threshold: False\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLUSTERING CONFIGURATION (TRAINING)\n",
    "# ============================================================================\n",
    "# Clustering thresholds\n",
    "INITIAL_THRESHOLD = 0.6      # Initial threshold (0.4-0.9)\n",
    "MIN_THRESHOLD = 0.4          # Minimum threshold (0.1-0.6)\n",
    "MAX_THRESHOLD = 0.7          # Maximum threshold (0.5-0.9)\n",
    "ADAPTIVE_THRESHOLD = False   # Disable adaptive adjustment\n",
    "# Merging parameters\n",
    "MIN_CLUSTER_SIZE = 3         # Minimum cluster size for merging (2-10)\n",
    "MERGE_SIMILARITY_THRESHOLD = 0.45  # Threshold for merging (0.3-0.7)\n",
    "# Training\n",
    "NUM_EPOCHS = 10              # Number of epochs (5-20)\n",
    "ENABLE_TRAINING = True       # Enable LoRA training\n",
    "ENABLE_MERGE = True          # Enable merging of small clusters\n",
    "print(\"[*] Clustering Configuration:\")\n",
    "print(f\"   - Thresholds: {INITIAL_THRESHOLD} / {MIN_THRESHOLD} / {MAX_THRESHOLD}\")\n",
    "print(f\"   - MIN_CLUSTER_SIZE: {MIN_CLUSTER_SIZE}\")\n",
    "print(f\"   - MERGE_SIMILARITY_THRESHOLD: {MERGE_SIMILARITY_THRESHOLD}\")\n",
    "print(f\"   - Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   - Adaptive threshold: {ADAPTIVE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Configuraci√≥n de Evaluaci√≥n:\n",
      "   - Modo: full\n",
      "   - Visualizaciones: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVALUATION CONFIGURATION\n",
    "# ============================================================================\n",
    "# Enable visualizations\n",
    "INCLUDE_VISUALIZATIONS = True  # Generate charts\n",
    "# Evaluation mode\n",
    "EVALUATION_MODE = 'full'  # 'learning', 'performance', o 'full'\n",
    "# Seebose\n",
    "VERBOSE = True  # Show detailed information\n",
    "print(\"[*] Configuration de Evaluaci√≥n:\")\n",
    "print(f\"   - Modo: {EVALUATION_MODE}\")\n",
    "print(f\"   - Visualizations: {INCLUDE_VISUALIZATIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-number-1\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M13 20v-16l-5 5\" /></svg> Training (Clustering)\n",
    "\n",
    "Run clustering with the configuration specified above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Dataset no encontrado: datasets/20newsgroups_sample_500.csv\n",
      "\n",
      "üí° Datasets disponibles:\n",
      "   - 20newsgroups.csv\n",
      "   - 20newsgroups_sample_200.csv\n",
      "   - 20newsgroups_sample_500.csv\n",
      "   - dataset_tests.csv\n",
      "   - mathematics_dataset2.csv\n",
      "   - pmc_open_access_sample.csv\n",
      "   - pmc_test_sample.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Dataset no encontrado: datasets/20newsgroups_sample_500.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(datasets_dir.glob(\u001b[33m'\u001b[39m\u001b[33m*.csv\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m      8\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset no encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Dataset no encontrado: datasets/20newsgroups_sample_500.csv"
     ]
    }
   ],
   "source": [
    "# Seeify that the dataset exists\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"[ERROR] Dataset not found: {DATASET_PATH}\")\n",
    "    print(\"\\n[TIP] Available datasets:\")\n",
    "    datasets_dir = project_root / 'datasets'\n",
    "    if datasets_dir.exists():\n",
    "        for f in sorted(datasets_dir.glob('*.csv')):\n",
    "            print(f\"   - {f.name}\")\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "print(\"=\" * 80)\n",
    "print(\"[XCTOPUS] INITIALIZING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "pipeline = XctopusPipeline(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    text_columns=TEXT_COLUMNS if TEXT_COLUMNS else None,\n",
    "    model_name=EMBEDDING_MODEL,\n",
    "    auto_detect_text_columns=(TEXT_COLUMNS is None)\n",
    ")\n",
    "print(\"[OK] Pipeline initialized\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust configuration\n",
    "config = pipeline.get_config()\n",
    "config.MIN_CLUSTER_SIZE = MIN_CLUSTER_SIZE\n",
    "config.MERGE_SIMILARITY_THRESHOLD = MERGE_SIMILARITY_THRESHOLD\n",
    "config.NUM_EPOCHS = NUM_EPOCHS\n",
    "print(\"[*] Configuration applied:\")\n",
    "print(f\"   - MIN_CLUSTER_SIZE: {config.MIN_CLUSTER_SIZE}\")\n",
    "print(f\"   - MERGE_SIMILARITY_THRESHOLD: {config.MERGE_SIMILARITY_THRESHOLD}\")\n",
    "print(f\"   - NUM_EPOCHS: {config.NUM_EPOCHS}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run clustering (Training)\n",
    "print(\"=\" * 80)\n",
    "print(\"[*] RUNNING CLUSTERING (TRAINING)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "result = pipeline.run(\n",
    "    step='clustering',\n",
    "    epochs=NUM_EPOCHS,\n",
    "    enable_training=ENABLE_TRAINING,\n",
    "    enable_merge=ENABLE_MERGE,\n",
    "    initial_threshold=INITIAL_THRESHOLD,\n",
    "    min_threshold=MIN_THRESHOLD,\n",
    "    max_threshold=MAX_THRESHOLD,\n",
    "    adaptive_threshold=ADAPTIVE_THRESHOLD\n",
    ")\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"[OK] CLUSTERING COMPLETED\")\n",
    "print(\"=\" * 80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show clustering results\n",
    "nodes = pipeline.get_nodes()\n",
    "print(f\"[*] Knowledge Nodes created: {len(nodes)}\")\n",
    "print()\n",
    "if nodes:\n",
    "    cluster_sizes = []\n",
    "    total_embeddings = 0\n",
    "    for cluster_id, node in nodes.items():\n",
    "        if hasattr(node, 'filter') and hasattr(node.filter, 'memory'):\n",
    "            memory = node.filter.memory\n",
    "            if isinstance(memory, dict) and cluster_id in memory:\n",
    "                cluster_size = len(memory[cluster_id])\n",
    "                cluster_sizes.append(cluster_size)\n",
    "                total_embeddings += cluster_size\n",
    "    if cluster_sizes:\n",
    "        print('[*] Cluster Statistics:')\n",
    "        print(f\"   - Total clusters: {len(cluster_sizes)}\")\n",
    "        print(f\"   - Total embeddings: {total_embeddings}\")\n",
    "        print(f\"   - Average per cluster: {sum(cluster_sizes)/len(cluster_sizes):.1f}\")\n",
    "        print(f\"   - Largest cluster: {max(cluster_sizes)}\")\n",
    "        print(f\"   - Smallest cluster: {min(cluster_sizes)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-number-2\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M10 8a2 2 0 1 1 4 0c0 .738 -.405 1.376 -1 1.723l-3 2.277v3h4\" /></svg> Evaluation\n",
    "\n",
    "Evaluate clustering quality and generate visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Audit\n",
    "print(\"=\" * 80)\n",
    "print('[*] RUNNING AUDIT')\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "try:\n",
    "    audit_result = pipeline.run(\n",
    "        step='audit',\n",
    "        dataset_path=DATASET_PATH,\n",
    "        verbose=VERBOSE,\n",
    "        include_visualization=INCLUDE_VISUALIZATIONS\n",
    "    )    \n",
    "    print()\n",
    "    print(\"[OK] Audit completed\")\n",
    "    print()\n",
    "    # Show audit summary\n",
    "    if 'audit' in pipeline.results:\n",
    "        audit_data = pipeline.results['audit']\n",
    "        if 'report' in audit_data:\n",
    "            report = audit_data['report']\n",
    "            print('[*] Audit Summary:')\n",
    "            if isinstance(report, dict):\n",
    "                for key, value in list(report.items())[:10]:  # Show first 10\n",
    "                    if key != 'detailed_analysis':\n",
    "                        print(f\"   - {key}: {value}\")\n",
    "            print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[WARNING]  Error during audit: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Evaluation\n",
    "print(\"=\" * 80)\n",
    "print(\"[*] RUNNING EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "try:\n",
    "    eval_result = pipeline.run(\n",
    "        step='evaluation',\n",
    "        mode=EVALUATION_MODE,\n",
    "        dataset_path=DATASET_PATH,\n",
    "        verbose=VERBOSE,\n",
    "        include_visualization=INCLUDE_VISUALIZATIONS\n",
    "    )\n",
    "    print()\n",
    "    print(\"[OK] Evaluation completed\")\n",
    "    print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[WARNING]  Error during evaluation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quality metrics\n",
    "if 'evaluation' in pipeline.results:\n",
    "    eval_data = pipeline.results['evaluation']\n",
    "    print(\"[*] Cluster Quality Metrics:\")\n",
    "    print()\n",
    "    if 'cluster_quality' in eval_data:\n",
    "        quality = eval_data['cluster_quality']\n",
    "        if isinstance(quality, dict):\n",
    "            if 'silhouette_score' in quality:\n",
    "                print(f\"   [OK] Silhouette Score: {quality['silhouette_score']:.4f}\")\n",
    "                print(f\"      (Range: -1 to 1, higher = better)\")\n",
    "            if 'davies_bouldin_score' in quality:\n",
    "                print(f\"   [OK] Davies-Bouldin Score: {quality['davies_bouldin_score']:.4f}\")\n",
    "                print(f\"      (Lower = better)\")\n",
    "            if 'cohesion' in quality:\n",
    "                print(f\"   [OK] Cohesion: {quality['cohesion']:.4f}\")\n",
    "            if 'sefortion' in quality:\n",
    "                print(f\"   [OK] Separation: {quality['sefortion']:.4f}\")\n",
    "            if 'n_clusters' in quality:\n",
    "                print(f\"   [OK] Number of clusters: {quality['n_clusters']}\")\n",
    "        print()\n",
    "    if 'performance_metrics' in eval_data:\n",
    "        perf = eval_data['performance_metrics']\n",
    "        print(\"‚ö° Performance Metrics:\")\n",
    "        if isinstance(perf, dict):\n",
    "            for key, value in perf.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"   - {key}: {value:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [*] Visualizations\n",
    "\n",
    "Charts are saved in `notebooks/`. Here you can visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "# List available charts\n",
    "viz_files = [\n",
    "    'embeddings_visualization.png',\n",
    "    'learning_progress.png',\n",
    "    'lora_changes_visualization.png',\n",
    "    'fragmentation_analysis.png'\n",
    "]\n",
    "print(\"[*] Available charts:\")\n",
    "print()\n",
    "for viz_file in viz_files:\n",
    "    viz_path = notebook_dir / viz_file\n",
    "    if viz_path.exists():\n",
    "        print(f\"[OK] {viz_file} ({viz_path.stat().st_size / 1024:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"[ERROR] {viz_file} (not found)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show embedding visualization\n",
    "embeddings_viz = notebook_dir / 'embeddings_visualization.png'\n",
    "if embeddings_viz.exists():\n",
    "    print(\"[*] Embedding Space Visualization:\")\n",
    "    display(Image(str(embeddings_viz), width=800))\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Chart not found. Run audit with include_visualization=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show learning progress\n",
    "learning_viz = notebook_dir / 'learning_progress.png'\n",
    "if learning_viz.exists():\n",
    "    print(\"[*] Learning Progress:\")\n",
    "    display(Image(str(learning_viz), width=1000))\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Chart not found. Run evaluation with include_visualization=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show LoRA changes\n",
    "lora_viz = notebook_dir / 'lora_changes_visualization.png'\n",
    "if lora_viz.exists():\n",
    "    print(\"[*] LoRA Parameter Changes:\")\n",
    "    display(Image(str(lora_viz), width=1000))\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Chart not found. Run evaluation with include_visualization=True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-notes\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M5 3m0 2a2 2 0 0 1 2 -2h10a2 2 0 0 1 2 2v14a2 2 0 0 1 -2 2h-10a2 2 0 0 1 -2 -2z\" /><path d=\"M9 7l6 0\" /><path d=\"M9 11l6 0\" /><path d=\"M9 15l4 0\" /></svg> Final Summary\n",
    "\n",
    "Summary de los resultados obtenidos:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [*] Automatic Results Analysis\n",
    "\n",
    "Intelligent analysis of results with automatic interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis autom√°tico e interpretaci√≥n de resultados\n",
    "\n",
    "def analyze_clustering_results(pipeline, config_forms):\n",
    "    \"\"\"Analyzes clustering results and provides interpretation\"\"\"\n",
    "    nodes = pipeline.get_nodes()\n",
    "    results = pipeline.get_results()\n",
    "    analysis = {\n",
    "        'summary': {},\n",
    "        'quality_assessment': {},\n",
    "        'recommendations': []\n",
    "    }\n",
    "    # Basic statistics\n",
    "    cluster_sizes = []\n",
    "    for cluster_id, node in nodes.items():\n",
    "        if hasattr(node, 'filter') and hasattr(node.filter, 'memory'):\n",
    "            memory = node.filter.memory\n",
    "            if isinstance(memory, dict) and cluster_id in memory:\n",
    "                cluster_sizes.append(len(memory[cluster_id]))\n",
    "    if cluster_sizes:\n",
    "        analysis['summary'] = {\n",
    "            'total_clusters': len(cluster_sizes),\n",
    "            'total_embeddings': sum(cluster_sizes),\n",
    "            'avg_cluster_size': np.mean(cluster_sizes),\n",
    "            'max_cluster_size': np.max(cluster_sizes),\n",
    "            'min_cluster_size': np.min(cluster_sizes),\n",
    "            'std_cluster_size': np.std(cluster_sizes)\n",
    "        }\n",
    "    # Quality metrics\n",
    "    if 'evaluation' in results:\n",
    "        eval_data = results['evaluation']\n",
    "        if 'cluster_quality' in eval_data:\n",
    "            quality = eval_data['cluster_quality']\n",
    "            analysis['quality_assessment'] = {\n",
    "                'silhouette_score': quality.get('silhouette_score', None),\n",
    "                'davies_bouldin_score': quality.get('davies_bouldin_score', None),\n",
    "                'cohesion': quality.get('cohesion', None),\n",
    "                'sefortion': quality.get('sefortion', None)\n",
    "            }\n",
    "    # Generate recommendations\n",
    "    if cluster_sizes:\n",
    "        avg_size = np.mean(cluster_sizes)\n",
    "        fragmentation_ratio = len(cluster_sizes) / sum(cluster_sizes) if sum(cluster_sizes) > 0 else 0\n",
    "        if fragmentation_ratio > 0.8:\n",
    "            analysis['recommendations'].append({\n",
    "                'issue': 'High fragmentation',\n",
    "                'severity': 'high',\n",
    "                'suggestion': 'Reduce INITIAL_THRESHOLD or MERGE_SIMILARITY_THRESHOLD'\n",
    "            })\n",
    "        if avg_size < 5:\n",
    "            analysis['recommendations'].append({\n",
    "                'issue': 'Seey small clusters',\n",
    "                'severity': 'medium',\n",
    "                'suggestion': 'Increase MERGE_SIMILARITY_THRESHOLD or reduce MIN_CLUSTER_SIZE'\n",
    "            })\n",
    "        if avg_size > 20:\n",
    "            analysis['recommendations'].append({\n",
    "                'issue': 'Seey large clusters',\n",
    "                'severity': 'low',\n",
    "                'suggestion': 'Increase INITIAL_THRESHOLD for crear m√°s clusters'\n",
    "            })\n",
    "    if 'silhouette_score' in analysis['quality_assessment']:\n",
    "        silhouette = analysis['quality_assessment']['silhouette_score']\n",
    "        if silhouette and silhouette < 0.5:\n",
    "            analysis['recommendations'].append({\n",
    "                'issue': 'Low clustering quality',\n",
    "                'severity': 'high',\n",
    "                'suggestion': 'Adjust thresholds or increase epochs'\n",
    "            })\n",
    "        elif silhouette and silhouette > 0.8:\n",
    "            analysis['recommendations'].append({\n",
    "                'issue': 'Excellent quality',\n",
    "                'severity': 'info',\n",
    "                'suggestion': '[OK] Configuration √≥ptima encontrada'\n",
    "            })\n",
    "    return analysis\n",
    "# Run analysis\n",
    "if 'pipeline' in locals():\n",
    "    config_forms = {\n",
    "        'INITIAL_THRESHOLD': INITIAL_THRESHOLD,\n",
    "        'MIN_THRESHOLD': MIN_THRESHOLD,\n",
    "        'MERGE_SIMILARITY_THRESHOLD': MERGE_SIMILARITY_THRESHOLD,\n",
    "        'NUM_EPOCHS': NUM_EPOCHS\n",
    "    }\n",
    "    analysis = analyze_clustering_results(pipeline, config_forms)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[*] AUTOMATIC RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    # Summary\n",
    "    if 'summary' in analysis:\n",
    "        print('[*] Summary:')\n",
    "        for key, value in analysis['summary'].items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"   - {key}: {value:.2f}\")\n",
    "            else:\n",
    "                print(f\"   - {key}: {value}\")\n",
    "        print()\n",
    "    # Calidad\n",
    "    if 'quality_assessment' in analysis:\n",
    "        print(\"[*] Clustering Quality:\")\n",
    "        quality = analysis['quality_assessment']\n",
    "        if quality.get('silhouette_score'):\n",
    "            score = quality['silhouette_score']\n",
    "            if score > 0.7:\n",
    "                status = \"[OK] Excellent\"\n",
    "            elif score > 0.5:\n",
    "                status = \"[OK] Good\"\n",
    "            else:\n",
    "                status = \"[WARNING]  Improvable\"\n",
    "            print(f\"   - Silhouette Score: {score:.4f} {status}\")\n",
    "        if quality.get('davies_bouldin_score'):\n",
    "            score = quality['davies_bouldin_score']\n",
    "            if score < 1.0:\n",
    "                status = \"[OK] Excellent\"\n",
    "            elif score < 1.5:\n",
    "                status = \"[OK] Good\"\n",
    "            else:\n",
    "                status = \"[WARNING]  Improvable\"\n",
    "            print(f\"   - Davies-Bouldin Score: {score:.4f} {status}\")\n",
    "        print()\n",
    "    # Recommendations\n",
    "    if analysis['recommendations']:\n",
    "        print(\"[TIP] Recommendations:\")\n",
    "        for rec in analysis['recommendations']:\n",
    "            severity_icon = {\n",
    "                'high': '<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-circle\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle; color: #ef4444;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0\" /></svg>',\n",
    "                'medium': '<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-circle\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle; color: #eab308;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0\" /></svg>',\n",
    "                'low': '<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-circle\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle; color: #22c55e;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0\" /></svg>',\n",
    "                'info': '[OK]'\n",
    "            }.get(rec['severity'], '<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-info-circle\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M3 12a9 9 0 1 0 18 0a9 9 0 0 0 -18 0\" /><path d=\"M12 9h.01\" /><path d=\"M11 12h1v4h1\" /></svg>')\n",
    "            print(f\"   {severity_icon} {rec['issue']}: {rec['suggestion']}\")\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Ejecuta primero el clustering for ver el an√°lisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [*] Configuration Comparison\n",
    "\n",
    "Comfor diferentes configuraciones lado a lado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comforci√≥n de configuraciones (opcional)\n",
    "# Descomenta y ejecuta for comforr m√∫ltiples configuraciones\n",
    "COMPARE_CONFIGS = False  # Cambiar a True for habilitar comforci√≥n\n",
    "if COMPARE_CONFIGS:\n",
    "    # Configuraciones a comforr\n",
    "    configs_to_test = [\n",
    "        {\n",
    "            'name': 'Current Config',\n",
    "            'INITIAL_THRESHOLD': INITIAL_THRESHOLD,\n",
    "            'MERGE_SIMILARITY_THRESHOLD': MERGE_SIMILARITY_THRESHOLD,\n",
    "            'NUM_EPOCHS': NUM_EPOCHS\n",
    "        },\n",
    "        {\n",
    "            'name': 'More Permissive',\n",
    "            'INITIAL_THRESHOLD': 0.5,\n",
    "            'MERGE_SIMILARITY_THRESHOLD': 0.4,\n",
    "            'NUM_EPOCHS': 10\n",
    "        },\n",
    "        {\n",
    "            'name': 'More Strict',\n",
    "            'INITIAL_THRESHOLD': 0.7,\n",
    "            'MERGE_SIMILARITY_THRESHOLD': 0.6,\n",
    "            'NUM_EPOCHS': 5\n",
    "        }\n",
    "    ]\n",
    "    comparison_results = []\n",
    "    print(\"[*] Comforndo configuraciones...\")\n",
    "    print()\n",
    "    for config in configs_to_test:\n",
    "        print(f\"[*] Testing: {config['name']}\")\n",
    "        # Here you would run clustering with each configuration\n",
    "        # For now, we only show the structure\n",
    "        comparison_results.append({\n",
    "            'Configuration': config['name'],\n",
    "            'INITIAL_THRESHOLD': config['INITIAL_THRESHOLD'],\n",
    "            'MERGE_SIMILARITY': config['MERGE_SIMILARITY_THRESHOLD'],\n",
    "            'Epochs': config['NUM_EPOCHS']\n",
    "        })\n",
    "    # Crear tabla comfortiva\n",
    "    df_comparison = pd.DataFrame(comparison_results)\n",
    "    display(HTML(df_comparison.to_html(index=False)))\n",
    "    print()\n",
    "    print(\"[TIP] Para comforr realmente, ejecuta el clustering con cada configuraci√≥n\")\n",
    "\n",
    "else:\n",
    "    print(\"[TIP] Para comforr configuraciones, cambia COMPARE_CONFIGS = True arriba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster distribution visualization\n",
    "if 'pipeline' in locals() and pipeline.get_nodes():\n",
    "    nodes = pipeline.get_nodes()\n",
    "    cluster_sizes = []\n",
    "    for cluster_id, node in nodes.items():\n",
    "        if hasattr(node, 'filter') and hasattr(node.filter, 'memory'):\n",
    "            memory = node.filter.memory\n",
    "            if isinstance(memory, dict) and cluster_id in memory:\n",
    "                cluster_sizes.append(len(memory[cluster_id]))\n",
    "    if cluster_sizes:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        # Histograma de tama√±os\n",
    "        axes[0].hist(cluster_sizes, bins=20, edgecolor='black', alpha=0.7)\n",
    "        axes[0].set_xlabel('Cluster Size')\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        axes[0].set_title('Cluster Size Distribution')\n",
    "        axes[0].axvline(np.mean(cluster_sizes), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(cluster_sizes):.1f}')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        # Box plot\n",
    "        axes[1].boxplot(cluster_sizes, vert=True)\n",
    "        axes[1].set_ylabel('Cluster Size')\n",
    "        axes[1].set_title('Size Distribution (Box Plot)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # Statistics\n",
    "        print(\"[*] Statistics de Distribuci√≥n:\")\n",
    "        print(f\"   - Mean: {np.mean(cluster_sizes):.2f}\")\n",
    "        print(f\"   - Meanna: {np.median(cluster_sizes):.2f}\")\n",
    "        print(f\"   - Standard deviation: {np.std(cluster_sizes):.2f}\")\n",
    "        print(f\"   - Range: {np.min(cluster_sizes)} - {np.max(cluster_sizes)}\")\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Ejecuta primero el clustering for ver las visualizaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual summary table of results\n",
    "if 'pipeline' in locals() and pipeline.get_nodes():\n",
    "    nodes = pipeline.get_nodes()\n",
    "    results = pipeline.get_results()\n",
    "    # Create summary table\n",
    "    summary_data = {\n",
    "        'Metric': [],\n",
    "        'Value': [],\n",
    "        'Status': []\n",
    "    }\n",
    "    # Basic statistics\n",
    "    cluster_sizes = []\n",
    "    for cluster_id, node in nodes.items():\n",
    "        if hasattr(node, 'filter') and hasattr(node.filter, 'memory'):\n",
    "            memory = node.filter.memory\n",
    "            if isinstance(memory, dict) and cluster_id in memory:\n",
    "                cluster_sizes.append(len(memory[cluster_id]))\n",
    "    if cluster_sizes:\n",
    "        summary_data['Metric'].extend([\n",
    "            'Total Clusters',\n",
    "            'Total Embeddings',\n",
    "            'Average per Cluster',\n",
    "            'Largest Cluster',\n",
    "            'Smallest Cluster'\n",
    "        ])\n",
    "        summary_data['Value'].extend([\n",
    "            len(cluster_sizes),\n",
    "            sum(cluster_sizes),\n",
    "            f\"{np.mean(cluster_sizes):.1f}\",\n",
    "            max(cluster_sizes),\n",
    "            min(cluster_sizes)\n",
    "        ])\n",
    "        summary_data['Status'].extend([\n",
    "            '[OK]' if len(cluster_sizes) < 500 else '[WARNING]',\n",
    "            '[OK]',\n",
    "            '[OK]' if np.mean(cluster_sizes) > 5 else '[WARNING]',\n",
    "            '[OK]',\n",
    "            '[OK]'\n",
    "        ])\n",
    "    # Quality metrics\n",
    "    if 'evaluation' in results:\n",
    "        eval_data = results['evaluation']\n",
    "        if 'cluster_quality' in eval_data:\n",
    "            quality = eval_data['cluster_quality']\n",
    "            if 'silhouette_score' in quality:\n",
    "                score = quality['silhouette_score']\n",
    "                summary_data['Metric'].append('Silhouette Score')\n",
    "                summary_data['Value'].append(f\"{score:.4f}\")\n",
    "                summary_data['Status'].append('[OK]' if score > 0.7 else '[WARNING]')\n",
    "            if 'davies_bouldin_score' in quality:\n",
    "                score = quality['davies_bouldin_score']\n",
    "                summary_data['Metric'].append('Davies-Bouldin Score')\n",
    "                summary_data['Value'].append(f\"{score:.4f}\")\n",
    "                summary_data['Status'].append('[OK]' if score < 1.0 else '[WARNING]')\n",
    "    # Create and show table\n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    display(HTML(df_summary.to_html(index=False, escape=False)))\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Ejecuta primero el clustering for ver la tabla resumen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-device-floppy\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M6 4h10l4 4v10a2 2 0 0 1 -2 2h-12a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2\" /><path d=\"M12 14m-2 0a2 2 0 1 0 4 0a2 2 0 1 0 -4 0\" /><path d=\"M14 4l0 4l-6 0l0 -4\" /></svg> Export Successful Configuration\n",
    "\n",
    "Guarda la configuraci√≥n que funcion√≥ bien for reutilizarla:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export successful configuration to YAML\n",
    "EXPORT_CONFIG = False  # Cambiar a True for exportar\n",
    "if EXPORT_CONFIG and 'pipeline' in locals():\n",
    "    # Seeify that results are good\n",
    "    nodes = pipeline.get_nodes()\n",
    "    results = pipeline.get_results()\n",
    "    # Evaluate if configuration is successful\n",
    "    is_successful = False\n",
    "    if 'evaluation' in results:\n",
    "        eval_data = results['evaluation']\n",
    "        if 'cluster_quality' in eval_data:\n",
    "            quality = eval_data['cluster_quality']\n",
    "            if quality.get('silhouette_score', 0) > 0.7:\n",
    "                is_successful = True\n",
    "    if is_successful or True:  # Always export if requested\n",
    "        config_to_export = {\n",
    "            'exported_at': datetime.now().isoformat(),\n",
    "            'dataset': DATASET_PATH,\n",
    "            'embedding_model': EMBEDDING_MODEL,\n",
    "            'clustering': {\n",
    "                'INITIAL_THRESHOLD': INITIAL_THRESHOLD,\n",
    "                'MIN_THRESHOLD': MIN_THRESHOLD,\n",
    "                'MAX_THRESHOLD': MAX_THRESHOLD,\n",
    "                'ADAPTIVE_THRESHOLD': ADAPTIVE_THRESHOLD,\n",
    "                'MIN_CLUSTER_SIZE': MIN_CLUSTER_SIZE,\n",
    "                'MERGE_SIMILARITY_THRESHOLD': MERGE_SIMILARITY_THRESHOLD,\n",
    "                'NUM_EPOCHS': NUM_EPOCHS\n",
    "            },\n",
    "            'results': {\n",
    "                'total_clusters': len(nodes),\n",
    "                'silhouette_score': results.get('evaluation', {}).get('cluster_quality', {}).get('silhouette_score', None)\n",
    "            }\n",
    "        }\n",
    "        # Save in docs/\n",
    "        export_path = project_root / 'docs' / f'config_exported_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.yaml'\n",
    "        export_path.parent.mkdir(exist_ok=True)\n",
    "        with open(export_path, 'w') as f:\n",
    "            yaml.dump(config_to_export, f, default_flow_style=False, sort_keys=False)\n",
    "        print(f\"[OK] Configuration exportada a: {export_path}\")\n",
    "        print()\n",
    "        print('[*] Configuration exportada:')\n",
    "        print(f\"   - Dataset: {DATASET_PATH}\")\n",
    "        print(f\"   - Clusters: {len(nodes)}\")\n",
    "        if 'evaluation' in results:\n",
    "            quality = results['evaluation'].get('cluster_quality', {})\n",
    "            if 'silhouette_score' in quality:\n",
    "                print(f\"   - Silhouette Score: {quality['silhouette_score']:.4f}\")\n",
    "    else:\n",
    "        print(\"[WARNING]  Los resultados no son suficientemente buenos for exportar\")\n",
    "        print(\"[TIP] Adjust parameters and try again\")\n",
    "\n",
    "else:\n",
    "    print(\"[TIP] To export configuration, change EXPORT_CONFIG = True above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [*] Results Dashboard\n",
    "\n",
    "Consolidated view of all results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete results dashboard\n",
    "if 'pipeline' in locals() and pipeline.get_nodes():\n",
    "    nodes = pipeline.get_nodes()\n",
    "    results = pipeline.get_results()\n",
    "    # Create HTML dashboard\n",
    "    dashboard_html = f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; padding: 20px;\">\n",
    "        <h2>[XCTOPUS] Xctopus - Results Dashboard</h2>\n",
    "        <div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px; margin-top: 20px;\">\n",
    "            <div style=\"border: 1px solid #ddd; padding: 15px; border-radius: 5px;\">\n",
    "                <h3>[*] Clustering Statistics</h3>\n",
    "    \"\"\"\n",
    "    # Statistics\n",
    "    cluster_sizes = []\n",
    "    for cluster_id, node in nodes.items():\n",
    "        if hasattr(node, 'filter') and hasattr(node.filter, 'memory'):\n",
    "            memory = node.filter.memory\n",
    "            if isinstance(memory, dict) and cluster_id in memory:\n",
    "                cluster_sizes.append(len(memory[cluster_id]))\n",
    "    if cluster_sizes:\n",
    "        dashboard_html += f\"\"\"\n",
    "                <p><strong>Total Clusters:</strong> {len(cluster_sizes)}</p>\n",
    "                <p><strong>Total Embeddings:</strong> {sum(cluster_sizes)}</p>\n",
    "                <p><strong>Average per Cluster:</strong> {np.mean(cluster_sizes):.1f}</p>\n",
    "                <p><strong>Largest Cluster:</strong> {max(cluster_sizes)}</p>\n",
    "                <p><strong>Smallest Cluster:</strong> {min(cluster_sizes)}</p>\n",
    "        \"\"\"\n",
    "    dashboard_html += \"\"\"\n",
    "            </div>\n",
    "            <div style=\"border: 1px solid #ddd; padding: 15px; border-radius: 5px;\">\n",
    "                <h3>[*] Quality Metrics</h3>\n",
    "    \"\"\"\n",
    "    # Quality metrics\n",
    "    if 'evaluation' in results:\n",
    "        eval_data = results['evaluation']\n",
    "        if 'cluster_quality' in eval_data:\n",
    "            quality = eval_data['cluster_quality']\n",
    "            if 'silhouette_score' in quality:\n",
    "                score = quality['silhouette_score']\n",
    "                color = 'green' if score > 0.7 else 'orange' if score > 0.5 else 'red'\n",
    "                dashboard_html += f\"\"\"\n",
    "                <p><strong>Silhouette Score:</strong> <span style=\"color: {color}; font-weight: bold;\">{score:.4f}</span></p>\n",
    "                \"\"\"\n",
    "            if 'davies_bouldin_score' in quality:\n",
    "                score = quality['davies_bouldin_score']\n",
    "                color = 'green' if score < 1.0 else 'orange' if score < 1.5 else 'red'\n",
    "                dashboard_html += f\"\"\"\n",
    "                <p><strong>Davies-Bouldin Score:</strong> <span style=\"color: {color}; font-weight: bold;\">{score:.4f}</span></p>\n",
    "                \"\"\"\n",
    "            if 'sefortion' in quality:\n",
    "                dashboard_html += f\"\"\"\n",
    "                <p><strong>Separation:</strong> {quality['sefortion']:.4f}</p>\n",
    "                \"\"\"\n",
    "    dashboard_html += \"\"\"\n",
    "            </div>\n",
    "            <div style=\"border: 1px solid #ddd; padding: 15px; border-radius: 5px;\">\n",
    "                <h3>[*] Configuration Usada</h3>\n",
    "    \"\"\"\n",
    "    dashboard_html += f\"\"\"\n",
    "                <p><strong>Dataset:</strong> {DATASET_PATH}</p>\n",
    "                <p><strong>Model:</strong> {EMBEDDING_MODEL}</p>\n",
    "                <p><strong>INITIAL_THRESHOLD:</strong> {INITIAL_THRESHOLD}</p>\n",
    "                <p><strong>MERGE_SIMILARITY:</strong> {MERGE_SIMILARITY_THRESHOLD}</p>\n",
    "                <p><strong>Epochs:</strong> {NUM_EPOCHS}</p>\n",
    "    \"\"\"\n",
    "    dashboard_html += \"\"\"\n",
    "            </div>\n",
    "            <div style=\"border: 1px solid #ddd; padding: 15px; border-radius: 5px;\">\n",
    "                <h3>[OK] Executed Steps</h3>\n",
    "    \"\"\"\n",
    "    if results:\n",
    "        steps = ', '.join(results.keys())\n",
    "        dashboard_html += f\"<p>{steps}</p>\"\n",
    "    dashboard_html += \"\"\"\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(dashboard_html))\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Ejecuta primero el clustering for ver el dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-chart-line\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M4 19l16 0\" /><path d=\"M4 15l4 -6l4 2l4 -5l4 4\" /></svg> Training Progress Charts\n",
    "\n",
    "Visualize how training evolved:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress if available\n",
    "if 'pipeline' in locals() and pipeline.get_results():\n",
    "    results = pipeline.get_results()\n",
    "    # Search for training data in results\n",
    "    training_data = None\n",
    "    if 'clustering' in results:\n",
    "        clustering_result = results['clustering']\n",
    "        if isinstance(clustering_result, dict) and 'training_history' in clustering_result:\n",
    "            training_data = clustering_result['training_history']\n",
    "    if training_data:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        # Loss per epoch\n",
    "        if 'losses' in training_data:\n",
    "            axes[0].plot(training_data['losses'], marker='o', linewidth=2, markersize=6)\n",
    "            axes[0].set_xlabel('Epoch')\n",
    "            axes[0].set_ylabel('Loss')\n",
    "            axes[0].set_title('Loss Evolution')\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            axes[0].set_yscale('log')  # Escala logar√≠tmica for mejor visualizaci√≥n\n",
    "        # Number of clusters por epoch\n",
    "        if 'n_clusters' in training_data:\n",
    "            axes[1].plot(training_data['n_clusters'], marker='s', color='green', linewidth=2, markersize=6)\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('Number of Clusters')\n",
    "            axes[1].set_title('Evoluci√≥n del Number of Clusters')\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"[TIP] Training progress data is not available\")\n",
    "        print(\"   This is normal if clustering was run without saving history\")\n",
    "\n",
    "else:\n",
    "    print(\"[WARNING]  Ejecuta primero el clustering for ver el progreso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TIP] Tips and Best Practices\n",
    "\n",
    "Consejos for obtener los mejores resultados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-target\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 12m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0\" /><path d=\"M12 12m-5 0a5 5 0 1 0 10 0a5 5 0 1 0 -10 0\" /><path d=\"M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0\" /></svg> Parameter Tuning\n",
    "\n",
    "**To reduce fragmentation (many small clusters):**\n",
    "- <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-arrow-down\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 5l0 14\" /><path d=\"M18 13l-6 6\" /><path d=\"M6 13l6 6\" /></svg> Reduce `INITIAL_THRESHOLD` (0.5-0.6)\n",
    "- <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-arrow-down\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 5l0 14\" /><path d=\"M18 13l-6 6\" /><path d=\"M6 13l6 6\" /></svg> Reduce `MERGE_SIMILARITY_THRESHOLD` (0.4-0.5)\n",
    "- <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-arrow-down\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 5l0 14\" /><path d=\"M18 13l-6 6\" /><path d=\"M6 13l6 6\" /></svg> Reduce `MIN_CLUSTER_SIZE` (2-3)\n",
    "- <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-arrow-up\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 5l0 14\" /><path d=\"M18 11l-6 -6\" /><path d=\"M6 11l6 -6\" /></svg> Increase `NUM_EPOCHS` (8-10)\n",
    "\n",
    "**To increase separation (more distinct clusters):**\n",
    "- <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-arrow-up\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 5l0 14\" /><path d=\"M18 11l-6 -6\" /><path d=\"M6 11l6 -6\" /></svg> Increase `INITIAL_THRESHOLD` (0.7-0.8)\n",
    "- <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-arrow-up\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 5l0 14\" /><path d=\"M18 11l-6 -6\" /><path d=\"M6 11l6 -6\" /></svg> Increase `MERGE_SIMILARITY_THRESHOLD` (0.6-0.7)\n",
    "- <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-arrow-up\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" style=\"vertical-align: middle;\"><path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M12 5l0 14\" /><path d=\"M18 11l-6 -6\" /><path d=\"M6 11l6 -6\" /></svg> Increase `MIN_CLUSTER_SIZE` (5-10)\n",
    "\n",
    "**For large datasets:**\n",
    "- Use `all-MiniLM-L6-v2` (faster)\n",
    "- Reduce `NUM_EPOCHS` initially (3-5)\n",
    "- Increase gradualmente seg√∫n resultados\n",
    "\n",
    "**For small datasets:**\n",
    "- Use `all-mpnet-base-v2` (more accurate)\n",
    "- Increase `NUM_EPOCHS` (10-15)\n",
    "- Stricter thresholds\n",
    "\n",
    "### [*] Metric Interpretation\n",
    "\n",
    "**Silhouette Score:**\n",
    "- `> 0.7`: [OK] Excellent separation\n",
    "- `0.5-0.7`: [OK] Good, puede mejorar\n",
    "- `< 0.5`: [WARNING] Review thresholds\n",
    "\n",
    "**Davies-Bouldin Score:**\n",
    "- `< 1.0`: [OK] Excellent\n",
    "- `1.0-1.5`: [OK] Good\n",
    "- `> 1.5`: [WARNING] Improvable\n",
    "\n",
    "**Average embeddings per cluster:**\n",
    "- `> 10`: [OK] Well consolidated clusters\n",
    "- `5-10`: [OK] Balanced\n",
    "- `< 5`: [WARNING] Possible fragmentation\n",
    "\n",
    "### [*] Experimentation Flow\n",
    "\n",
    "1. **Start conservative**: High thresholds, few epochs\n",
    "2. **Evaluate results**: Revisar an√°lisis autom√°tico\n",
    "3. **Gradually adjust**: One parameter at a time\n",
    "4. **Comforr configuraciones**: Use secci√≥n de comforci√≥n\n",
    "5. **Export successful ones**: Save configs that work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"[*] FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "nodes = pipeline.get_nodes()\n",
    "results = pipeline.get_results()\n",
    "print(f\"[*] Dataset: {DATASET_PATH}\")\n",
    "print(f\"[*] Model: {EMBEDDING_MODEL}\")\n",
    "print(f\"[*] Clusters created: {len(nodes)}\")\n",
    "print(f\"[OK] Executed steps: {', '.join(results.keys())}\")\n",
    "print()\n",
    "# Statistics de clusters\n",
    "if nodes:\n",
    "    cluster_sizes = []\n",
    "    for cluster_id, node in nodes.items():\n",
    "        if hasattr(node, 'filter') and hasattr(node.filter, 'memory'):\n",
    "            memory = node.filter.memory\n",
    "            if isinstance(memory, dict) and cluster_id in memory:\n",
    "                cluster_sizes.append(len(memory[cluster_id]))\n",
    "    if cluster_sizes:\n",
    "        print('[*] Statistics:')\n",
    "        print(f\"   - Average per cluster: {sum(cluster_sizes)/len(cluster_sizes):.1f}\")\n",
    "        print(f\"   - Largest cluster: {max(cluster_sizes)}\")\n",
    "        print(f\"   - Smallest cluster: {min(cluster_sizes)}\")\n",
    "        print()\n",
    "# Quality metrics\n",
    "if 'evaluation' in results:\n",
    "    eval_data = results['evaluation']\n",
    "    if 'cluster_quality' in eval_data:\n",
    "        quality = eval_data['cluster_quality']\n",
    "        if isinstance(quality, dict):\n",
    "            print(\"[*] Quality Metrics:\")\n",
    "            if 'silhouette_score' in quality:\n",
    "                print(f\"   - Silhouette Score: {quality['silhouette_score']:.4f}\")\n",
    "            if 'davies_bouldin_score' in quality:\n",
    "                print(f\"   - Davies-Bouldin Score: {quality['davies_bouldin_score']:.4f}\")\n",
    "            print()\n",
    "print(\"[TIP] To change parameters, modify the configuration cells above\")\n",
    "print(\"[TIP] To change dataset, modify DATASET_PATH in the configuration cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### [*] Tips and Recommendations\n",
    "\n",
    "### For Better Grouping:\n",
    "- Reduce `INITIAL_THRESHOLD` (0.5-0.6)\n",
    "- Reduce `MERGE_SIMILARITY_THRESHOLD` (0.4-0.5)\n",
    "- Increase `NUM_EPOCHS` (10-15)\n",
    "\n",
    "### For Smaller Clusters:\n",
    "- Increase `INITIAL_THRESHOLD` (0.7-0.8)\n",
    "- Increase `MERGE_SIMILARITY_THRESHOLD` (0.6-0.7)\n",
    "\n",
    "### For Better Performance:\n",
    "- Use `all-MiniLM-L6-v2` (faster)\n",
    "- Reduce `NUM_EPOCHS` si es necesario\n",
    "\n",
    "### Available Datasets:\n",
    "- `datasets/20newsgroups.csv` - Complete dataset\n",
    "- `datasets/20newsgroups_sample_500.csv` - Sample of 500\n",
    "- `datasets/pmc_open_access_sample.csv` - Scientific articles\n",
    "\n",
    "See `docs/TEST_RESULTS_20NEWSGROUPS.md` for m√°s detalles sobre configuraciones probadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
